# Human Activity Recognition Using Smartphones Dataset - post processing
by: Arash Jahaniri

## The repo includes the following files
* 'run_analysis.R' that is the R script to perform the required tasks
* 'dataset1.txt' that is the first new data set generated by the R code (variable names are excluded)
* 'dataset1.txt' that is the second new data set generated by the R code (variable names are excluded)
* 'CodeBook.md' that describes the variables, the data, and any transformations or work performed to clean up the data 
* 'README.md' that explains how all of the scripts work
* 'README-original.md' that present the the README file of the original data sets
* 'features-original.md' that presents the information on the original set of features

## Description
The post processing was carried out to generate two tidy data sets using original data sets. To find information on the original data sets and the original features see the following two files:
* README-original.md
* features-original.md

## Procedure
An R script called run_analysis.R was written to perform the following 5 tasks to generate the two tidy data sets:
* task 1: Merge the training and the test sets (from the original data set) to create one data set.
* task 2: Extract only the measurements on the mean and standard deviation for each measurement.
* task 3: Use descriptive activity names to name the activities in the data set
* task 4: Appropriately label the data set with descriptive variable names. (This is the first new tidy data set)
* task 5: From the data set in step 4, create a second, independent tidy data set with the average of each variable for each activity and each subject. (This is the second new tidy data set)

To carry out the above mentioned tasks, the R script performs the following steps:
(these steps also appear in the R script as comments)
### setting the working directory
### making a project folder
### downloading the zip file
### extracting (unzipping) the downloaded zip file in the project folder
### reading feature(variable) names
### reading activity types (1 through 6) with the associated descriptions
### reading subject IDs for the test data set
### labelling the variable with a descriptive name.
### reading features (variables) of the test data set
### labelling the variables with descriptive names.
### reading labels of the test data set
### labelling the variable with a descriptive name.
### reading subject IDs for the train data set
### labelling the variable with a descriptive name.
### reading features (variables) of the train data set
### labelling the variables with descriptive names.
### reading labels of the train data set
### labelling the variable with a descriptive name.
### combining the label, subject ID, and the features of the test data set
### combining the label, subject ID, and the features of the train data set
### combining the test and train data sets
### finding column indices where mean was measured (searching the key word mean in variable names)
### finding column indices where std was measured (searching the key word std in variable names)
### finding column indices where mean or std was measured
### extracting the required data, keeping columns 1 (label) and 2 (subject ID)
### making sure there are only 6 activity types
### creating a categorical variable to present descriptive activity names
### adding the categorical variable created in the previous step to the extracted data to have the final data set
### converting the integer class of the sunjectID variable into factor class
### splitting the data based on the following two categorical factors: 
* labelFactor (different activities), and 
* subjectID (different subjects)
### using lapply to find the mean of each variable for each activity type and each subject ID. 
the first three variables (columns) are excluded from mean calculation because they are not sensor measurements, these three variables are:
* 1) labelFactor {STANDING, LAYING, ...}
* 2) label {1, 2, ..., 5}
* 3) subjectID {1, 2, ..., 30}
### using rbind_all to combine all data frames stored in a list into one single dataframe
### writing the two new tidy data sets in the desired folder 




